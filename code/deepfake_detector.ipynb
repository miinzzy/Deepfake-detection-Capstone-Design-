{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWnN0R20nye5"
      },
      "source": [
        "## train.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz3dWjBivS7K",
        "outputId": "facd7b97-92a0-420e-95d4-9924a945aedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzjDv41lnye9",
        "outputId": "9c8f4aa3-8be0-4bd4-ec27-2f3bfe98a3dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 17 09:01:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwFs4-w2nyfB"
      },
      "outputs": [],
      "source": [
        "import easydict\n",
        "import os\n",
        "import sys\n",
        "from PIL import Image\n",
        "import tqdm\n",
        "import shutil\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torchvision import transforms\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from torchvision.models import VGG\n",
        "from torchvision.models.vgg import make_layers"
      ],
      "metadata": {
        "id": "eViI-h9DqZsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 719\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "FL5d2ORw9-a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 공격함수"
      ],
      "metadata": {
        "id": "M6vF1yv4CHqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "real_train_path = \"/content/drive/My Drive/deepfake/real/train/\"\n",
        "fake_train_path = \"/content/drive/My Drive/deepfake/fake/train/\"\n",
        "real_valid_path = \"/content/drive/My Drive/deepfake/real/valid/\"\n",
        "fake_valid_path = \"/content/drive/My Drive/deepfake/fake/valid/\""
      ],
      "metadata": {
        "id": "H7EQqOqCjgMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_realnoise_train_path = \"/content/drive/My Drive/deepfake/new/train/real/\"\n",
        "save_fakenoise_train_path = \"/content/drive/My Drive/deepfake/new/train/fake/\"\n",
        "save_realnoise_valid_path = \"/content/drive/My Drive/deepfake/new/valid/real/\"\n",
        "save_fakenoise_valid_path = \"/content/drive/My Drive/deepfake/new/valid/fake/\""
      ],
      "metadata": {
        "id": "vD4ror2Xj0r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_train_list = os.listdir(real_train_path)\n",
        "fake_train_list = os.listdir(fake_train_path)\n",
        "real_valid_list = os.listdir(real_valid_path)\n",
        "fake_valid_list = os.listdir(fake_valid_path)"
      ],
      "metadata": {
        "id": "wiwZheGbkUG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(real_train_list))\n",
        "print(len(fake_train_list))\n",
        "print(len(real_valid_list))\n",
        "print(len(fake_valid_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeIqh3871eUR",
        "outputId": "a1ce8868-95a2-43e8-981c-70cd0420c974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n",
            "2500\n",
            "900\n",
            "900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(save_realnoise_train_path)))\n",
        "print(len(os.listdir(save_fakenoise_train_path)))\n",
        "print(len(os.listdir(save_realnoise_valid_path)))\n",
        "print(len(os.listdir(save_fakenoise_valid_path)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKOTtKVS7dO-",
        "outputId": "d48141fa-0b96-47ca-cb80-ada88172d91b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_attack_params(attack_name):\n",
        "#     attack_dict = {\n",
        "#         'gaussian_noise': {'noise_std': (30, 300)},\n",
        "#         'sharpening' : {'center' : (1, 5)},\n",
        "#         'jpeg' : {'quality' : (5, 95)},\n",
        "#         'gaussian_blur' : {'ksize' : (2, 20)},\n",
        "#         # 'unsharp_mask' : {'amount' : (2, 20)},\n",
        "#         'universal_perturbation' : {'level' : (0.05, 0.5)}\n",
        "#     }\n",
        "\n",
        "#     return attack_dict[attack_name.lower()]"
      ],
      "metadata": {
        "id": "yixuNfChi2t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_attack_params(attack_name):\n",
        "    attack_dict = {\n",
        "        'gaussian_noise': {'noise_std': (30, 210)},\n",
        "        'sharpening' : {'center' : (0.5, 3.5)},\n",
        "        'jpeg' : {'quality' : (35, 90)},\n",
        "        'median_blur' : {'ksize' : (2, 15)},\n",
        "        'universal_perturbation' : {'level' : (0.05, 0.35)}\n",
        "    }\n",
        "\n",
        "    return attack_dict[attack_name.lower()]"
      ],
      "metadata": {
        "id": "flgTV68YoIY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sharpening(Function):\n",
        "\n",
        "    def forward(ctx, image):\n",
        "        (start, end) = get_attack_params('sharpening')['center']\n",
        "        i = np.random.uniform(start, end)\n",
        "        sharpening_arr = np.array([[0, -i, 0],\n",
        "                                   [-i, 4*i+1, -i],\n",
        "                                   [0, -i, 0]])\n",
        "        output = cv2.filter2D(image, -1, sharpening_arr)\n",
        "        return output"
      ],
      "metadata": {
        "id": "0NQ3bmaTx0Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianNoise(Function):\n",
        "    \n",
        "    def forward(ctx,image):\n",
        "        (start, end) = get_attack_params('gaussian_noise')['noise_std']\n",
        "        noise_std = np.random.uniform(start, end)\n",
        "        mean = 0\n",
        "        sigma = noise_std ** 0.5\n",
        "        gauss = np.random.normal(mean, sigma,image.shape)\n",
        "        res = image + gauss\n",
        "        noisy = np.clip(res, 0, 255).astype(np.uint8)\n",
        "        return noisy"
      ],
      "metadata": {
        "id": "4Y0_rF76kJmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class GaussianBlur(Function):\n",
        "\n",
        "#     def forward(ctx, image):\n",
        "#         (start, end) = get_attack_params('gaussian_blur')['ksize']\n",
        "#         ksize = np.random.uniform(start, end)\n",
        "#         ksize = int(ksize)\n",
        "#         if ksize % 2 == 0:\n",
        "#             i = ksize + 1\n",
        "#         else:\n",
        "#             i = ksize\n",
        "#         blur_img = cv2.GaussianBlur(image, (i, i) , 0)\n",
        "#         return blur_img"
      ],
      "metadata": {
        "id": "cyOAPtJLiOCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MedianBlur(Function):\n",
        "\n",
        "    def forward(ctx, image):\n",
        "        (start, end) = get_attack_params('median_blur')['ksize']\n",
        "        ksize = np.random.uniform(start, end)\n",
        "        ksize = int(ksize)\n",
        "        if ksize % 2 == 0:\n",
        "            i = ksize + 1\n",
        "        else:\n",
        "            i = ksize\n",
        "        blur_img = cv2.medianBlur(image, i)\n",
        "        return blur_img"
      ],
      "metadata": {
        "id": "mg_UAwtUH1RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class unsharp_mask(Function):\n",
        "\n",
        "#     def forward(ctx, image):\n",
        "#         (start, end) = get_attack_params('unsharp_mask')['amount']\n",
        "#         amount = np.random.uniform(start, end)\n",
        "#         result = unsharp_mask(image, radius=3, amount=amount)\n",
        "#         result = cv2.convertScaleAbs(result, alpha=(255.0))\n",
        "#         return result"
      ],
      "metadata": {
        "id": "SJmPW3ZRiX2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UniversalPerturbation(Function):\n",
        "\n",
        "    def forward(ctx, image):\n",
        "        pert_path = '/content/drive/My Drive/deepfake/perturbation_classification/googlenet_no_data.npy'\n",
        "        pert_ndarr = np.load(pert_path)\n",
        "        pert_ndarr = np.squeeze(pert_ndarr)\n",
        "\n",
        "        pert_img = Image.fromarray(pert_ndarr, 'RGB')\n",
        "        pert_img = pert_img.resize((960, 540))\n",
        "        np_pert = np.asarray(pert_img)\n",
        "\n",
        "        # img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        np_human = np.asarray(image)\n",
        "\n",
        "        (start, end) = get_attack_params('universal_perturbation')['level']\n",
        "        level = np.random.uniform(start, end)\n",
        "\n",
        "        np_pert = np_pert * level\n",
        "        np_pert = np_pert.astype(int)\n",
        "        np_pert = np.clip(np_pert, 0, 255)\n",
        "\n",
        "        np_plus = np_pert + np_human.astype(int)\n",
        "        np_plus = np.clip(np_plus, 0, 255)\n",
        "\n",
        "        # plus_img = Image.fromarray(np_plus.astype('uint8'), 'RGB')\n",
        "        \n",
        "        return np_plus"
      ],
      "metadata": {
        "id": "qjzl26v9WW5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_attack():\n",
        "    \n",
        "    attacks1 = [MedianBlur.apply]\n",
        "    attacks2 = [GaussianNoise.apply, Sharpening.apply, UniversalPerturbation.apply]\n",
        "    random.shuffle(attacks2)  \n",
        "    attacks = attacks1 + attacks2\n",
        "\n",
        "    return attacks"
      ],
      "metadata": {
        "id": "kxDdpM6GmRpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def go(real_train_list, fake_train_list, real_valid_list, fake_valid_list):\n",
        "\n",
        "    attacks = fetch_attack()\n",
        "    global train_realnoise\n",
        "    global train_fakenoise\n",
        "    global valid_realnoise\n",
        "    global valid_fakenoise\n",
        "    for real_img in real_train_list:\n",
        "        img = real_train_path + real_img\n",
        "        train_realnoise = cv2.imread(img)\n",
        "        for attack in attacks:\n",
        "            train_realnoise = attack(train_realnoise)\n",
        "        # JPEG 적용\n",
        "        (start, end) = get_attack_params('jpeg')['quality']\n",
        "        noise_amount = np.random.uniform(start, end)\n",
        "        save_path = save_realnoise_train_path + real_img\n",
        "        cv2.imwrite(save_path, train_realnoise, [cv2.IMWRITE_JPEG_QUALITY, noise_amount])\n",
        "\n",
        "    for fake_img in fake_train_list:\n",
        "        img = fake_train_path + fake_img\n",
        "        train_fakenoise = cv2.imread(img)\n",
        "        for attack in attacks:\n",
        "            train_fakenoise = attack(train_fakenoise)\n",
        "        # JPEG 적용\n",
        "        (start, end) = get_attack_params('jpeg')['quality']\n",
        "        noise_amount = np.random.uniform(start, end)\n",
        "        save_path = save_fakenoise_train_path + fake_img\n",
        "        cv2.imwrite(save_path, train_fakenoise, [cv2.IMWRITE_JPEG_QUALITY, noise_amount])\n",
        "\n",
        "    for real_img in real_valid_list:\n",
        "        img = real_valid_path + real_img\n",
        "        valid_realnoise = cv2.imread(img)\n",
        "        for attack in attacks:\n",
        "            valid_realnoise = attack(valid_realnoise)\n",
        "        # JPEG 적용\n",
        "        (start, end) = get_attack_params('jpeg')['quality']\n",
        "        noise_amount = np.random.uniform(start, end)\n",
        "        save_path = save_realnoise_valid_path +real_img\n",
        "        cv2.imwrite(save_path, valid_realnoise, [cv2.IMWRITE_JPEG_QUALITY, noise_amount])\n",
        "\n",
        "    for fake_img in fake_valid_list:\n",
        "        img = fake_valid_path + fake_img\n",
        "        valid_fakenoise = cv2.imread(img)\n",
        "        for attack in attacks:\n",
        "            valid_fakenoise = attack(valid_fakenoise)\n",
        "        # JPEG 적용\n",
        "        (start, end) = get_attack_params('jpeg')['quality']\n",
        "        noise_amount = np.random.uniform(start, end)\n",
        "        save_path = save_fakenoise_valid_path + fake_img\n",
        "        cv2.imwrite(save_path, valid_fakenoise, [cv2.IMWRITE_JPEG_QUALITY, noise_amount])"
      ],
      "metadata": {
        "id": "9oMKR-lVpDuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "go(real_train_list, fake_train_list, real_valid_list, fake_valid_list)"
      ],
      "metadata": {
        "id": "8BHz7krlq6QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir(save_realnoise_train_path)))\n",
        "print(len(os.listdir(save_fakenoise_train_path)))\n",
        "print(len(os.listdir(save_realnoise_valid_path)))\n",
        "print(len(os.listdir(save_fakenoise_valid_path)))"
      ],
      "metadata": {
        "id": "d1EYyNBzFR41",
        "outputId": "db5c2f85-ee5d-4246-af93-28c3ea0309a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2500\n",
            "2500\n",
            "900\n",
            "900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## txt 파일 만들기"
      ],
      "metadata": {
        "id": "N2TSMojjZ53G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_list_txt = \"/content/drive/My Drive/deepfake/new_train_list.txt\""
      ],
      "metadata": {
        "id": "aYqAArt84Isl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = os.listdir(real_train_path)\n",
        "str_a = \"real/train/\" + \" 0\\nreal/train/\".join(a) + \" 0\\n\"\n",
        "f = open(train_list_txt, 'w')\n",
        "f.write(str_a)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "kne-5cjG-x3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = os.listdir(fake_train_path)\n",
        "str_b = \"fake/train/\" + \" 1\\nfake/train/\".join(b) + \" 1\\n\"\n",
        "f = open(train_list_txt, 'a')\n",
        "f.write(str_b)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "akNlke6n-x3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = os.listdir(save_realnoise_train_path)\n",
        "str_c = \"new/train/real/\" + \" 0\\nnew/train/real/\".join(c) + \" 0\\n\"\n",
        "f = open(train_list_txt, 'a')\n",
        "f.write(str_c)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "sKp7Gx0O-x3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = os.listdir(save_fakenoise_train_path)\n",
        "str_d = \"new/train/fake/\" + \" 1\\nnew/train/fake/\".join(d) + \" 1\\n\"\n",
        "f = open(train_list_txt, 'a')\n",
        "f.write(str_d)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "_hf14A9s-x3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_list_txt = \"/content/drive/My Drive/deepfake/new_valid_list.txt\""
      ],
      "metadata": {
        "id": "f5_yBs5W_qmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = os.listdir(real_valid_path)\n",
        "str_a = \"real/valid/\" + \" 0\\nreal/valid/\".join(a) + \" 0\\n\"\n",
        "f = open(valid_list_txt, 'w')\n",
        "f.write(str_a)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "nWIsAPwCATIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = os.listdir(fake_valid_path)\n",
        "str_b = \"fake/valid/\" + \" 1\\nfake/valid/\".join(b) + \" 1\\n\"\n",
        "f = open(valid_list_txt, 'a')\n",
        "f.write(str_b)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "BjXHjGYHATId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = os.listdir(save_realnoise_valid_path)\n",
        "str_c = \"new/valid/real/\" + \" 0\\nnew/valid/real/\".join(c) + \" 0\\n\"\n",
        "f = open(valid_list_txt, 'a')\n",
        "f.write(str_c)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "OFQt34kHATIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = os.listdir(save_fakenoise_valid_path)\n",
        "str_d = \"new/valid/fake/\" + \" 1\\nnew/valid/fake/\".join(d) + \" 1\\n\"\n",
        "f = open(valid_list_txt, 'a')\n",
        "f.write(str_d)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "M-rKB1NJATIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ra9g75RnyfA"
      },
      "source": [
        "## 1. 기본 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPZ91U53nyfB"
      },
      "outputs": [],
      "source": [
        "cudnn.benchmark = True\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "    \"gpu\": 0,\n",
        "    \"num_workers\": 32,\n",
        "\n",
        "    \"root\": \"/content/drive/My Drive/deepfake\",\n",
        "    \"train_list\": \"/content/drive/My Drive/deepfake/new_train_list.txt\",\n",
        "    \"valid_list\": \"/content/drive/My Drive/deepfake/new_valid_list.txt\",\n",
        "\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"num_epochs\": 10,\n",
        "    \"batch_size\": 32,\n",
        "\n",
        "    \"save_fn\": \"/content/drive/My Drive/deepfake/model/xception_new_model_result.pth.tar\",\n",
        "})\n",
        "\n",
        "assert os.path.isfile(args.train_list), 'wrong path'\n",
        "assert os.path.isfile(args.valid_list), 'wrong path'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH71rXjKnyfC"
      },
      "source": [
        "## 2. 모델\n",
        "- 참고문헌\\[1]\\[2]에 따르면 Xception\\[3] 모델이 변조 영상 탐지에 가장 좋은 성능을 보여주어 해당 모델을 기본 모델로 선정\n",
        "\n",
        "\\[1] FaceForensics++: Learning to Detect Manipulated Facial Images, ICCV 2019.  \n",
        "\\[2] A Large-scale Challenging Dataset for DeepFace Forensics, CVPR 2020.  \n",
        "\\[3] Xception: Deep Learning with Depthwise Seperable Convolutions, CVPR 2017."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcMsS3NdnyfD"
      },
      "source": [
        "### 3-1 Xception 구현\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk6OOSnknyfD"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Author: Andreas Rössler,\n",
        "Implemented in https://github.com/ondyari/FaceForensics under MIT license\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n",
        "        super(SeparableConv2d,self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self,in_filters,out_filters,reps,strides=1,start_with_relu=True,grow_first=True):\n",
        "        super(Block, self).__init__()\n",
        "\n",
        "        if out_filters != in_filters or strides!=1:\n",
        "            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n",
        "            self.skipbn = nn.BatchNorm2d(out_filters)\n",
        "        else:\n",
        "            self.skip=None\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        rep=[]\n",
        "\n",
        "        filters=in_filters\n",
        "        if grow_first:\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(out_filters))\n",
        "            filters = out_filters\n",
        "\n",
        "        for i in range(reps-1):\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(filters))\n",
        "\n",
        "        if not grow_first:\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(out_filters))\n",
        "\n",
        "        if not start_with_relu:\n",
        "            rep = rep[1:]\n",
        "        else:\n",
        "            rep[0] = nn.ReLU(inplace=False)\n",
        "\n",
        "        if strides != 1:\n",
        "            rep.append(nn.MaxPool2d(3,strides,1))\n",
        "        self.rep = nn.Sequential(*rep)\n",
        "\n",
        "    def forward(self,inp):\n",
        "        x = self.rep(inp)\n",
        "\n",
        "        if self.skip is not None:\n",
        "            skip = self.skip(inp)\n",
        "            skip = self.skipbn(skip)\n",
        "        else:\n",
        "            skip = inp\n",
        "\n",
        "        x+=skip\n",
        "        return x\n",
        "\n",
        "\n",
        "class Xception(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(Xception, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3,32,3,2,0,bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32,64,3,bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.block1=Block(64,128,2,2,start_with_relu=False,grow_first=True)\n",
        "        self.block2=Block(128,256,2,2,start_with_relu=True,grow_first=True)\n",
        "        self.block3=Block(256,728,2,2,start_with_relu=True,grow_first=True)\n",
        "\n",
        "        self.block4=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block5=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block6=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block7=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "\n",
        "        self.block8=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block9=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block10=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block11=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "\n",
        "        self.block12=Block(728,1024,2,2,start_with_relu=True,grow_first=False)\n",
        "\n",
        "        self.conv3 = SeparableConv2d(1024,1536,3,1,1)\n",
        "        self.bn3 = nn.BatchNorm2d(1536)\n",
        "\n",
        "        self.conv4 = SeparableConv2d(1536,2048,3,1,1)\n",
        "        self.bn4 = nn.BatchNorm2d(2048)\n",
        "\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "    def features(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "        x = self.block7(x)\n",
        "        x = self.block8(x)\n",
        "        x = self.block9(x)\n",
        "        x = self.block10(x)\n",
        "        x = self.block11(x)\n",
        "        x = self.block12(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        return x\n",
        "\n",
        "    def logits(self, features):\n",
        "        x = self.relu(features)\n",
        "\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1)) \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.last_linear(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.features(input)\n",
        "        x = self.logits(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "## 기존 Xception에 Dropout만 추가\n",
        "class xception(nn.Module):\n",
        "    def __init__(self, num_out_classes=2, dropout=0.5):\n",
        "        super(xception, self).__init__()\n",
        "\n",
        "        self.model = Xception(num_classes=num_out_classes)\n",
        "        self.model.last_linear = self.model.fc\n",
        "        del self.model.fc\n",
        "\n",
        "        num_ftrs = self.model.last_linear.in_features\n",
        "        if not dropout:\n",
        "            self.model.last_linear = nn.Linear(num_ftrs, num_out_classes)\n",
        "        else:            \n",
        "            self.model.last_linear = nn.Sequential(\n",
        "                nn.Dropout(p=dropout),\n",
        "                nn.Linear(num_ftrs, num_out_classes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cfdqV1GnyfG"
      },
      "source": [
        "### 2-2. Pretrained Weight\n",
        "- FaceForensics++ 데이터로 학습된 pre-trained model weight 다운\\[4]\n",
        "\n",
        "\\[4]https://github.com/HongguLiu/Deepfake-Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09llpGXQnyfH",
        "outputId": "0a8f0619-70ce-4a16-f5d3-11e397f2528b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-17 09:02:12--  https://docs.google.com/uc?export=download&id=1eHRN117X0loEff7EBk1mGMJeGbGKsd7m\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.148.100, 142.250.148.102, 142.250.148.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.148.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0c-2k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/dfop74h5unqqe80pl1nketg7if6grnsu/1655456475000/05567444099345578170/*/1eHRN117X0loEff7EBk1mGMJeGbGKsd7m?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-06-17 09:02:17--  https://doc-0c-2k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/dfop74h5unqqe80pl1nketg7if6grnsu/1655456475000/05567444099345578170/*/1eHRN117X0loEff7EBk1mGMJeGbGKsd7m?e=download\n",
            "Resolving doc-0c-2k-docs.googleusercontent.com (doc-0c-2k-docs.googleusercontent.com)... 74.125.126.132, 2607:f8b0:4001:c1d::84\n",
            "Connecting to doc-0c-2k-docs.googleusercontent.com (doc-0c-2k-docs.googleusercontent.com)|74.125.126.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83519096 (80M) [application/octet-stream]\n",
            "Saving to: ‘deepfake_c0_xception.pkl’\n",
            "\n",
            "deepfake_c0_xceptio 100%[===================>]  79.65M   118MB/s    in 0.7s    \n",
            "\n",
            "2022-06-17 09:02:18 (118 MB/s) - ‘deepfake_c0_xception.pkl’ saved [83519096/83519096]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O deepfake_c0_xception.pkl --no-check-certificate 'https://docs.google.com/uc?export=download&id=1eHRN117X0loEff7EBk1mGMJeGbGKsd7m'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-WCz0rtnyfI"
      },
      "source": [
        "## 3. 훈련"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biyHgj7fnyfI"
      },
      "source": [
        "### 3-1 전처리\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXVyfMNmnyfI"
      },
      "outputs": [],
      "source": [
        "xception_default = {\n",
        "    'train': transforms.Compose([transforms.CenterCrop((299, 299)),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.RandomHorizontalFlip(),\n",
        "                                 transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "                                 ]),\n",
        "    'valid': transforms.Compose([transforms.CenterCrop((299, 299)),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "                                 ]),\n",
        "    'test': transforms.Compose([transforms.CenterCrop((299, 299)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.5] * 3, [0.5] * 3),\n",
        "                                ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3cd_TkznyfJ"
      },
      "source": [
        "### 3-2 Train/Validate/Dataset 함수\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X82IQt3WnyfJ"
      },
      "outputs": [],
      "source": [
        "# util\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch, args):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = args.lr * (0.1 ** (epoch // 30))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MveB95lnyfJ"
      },
      "outputs": [],
      "source": [
        "# custom dataset\n",
        "\n",
        "class ImageRecord(object):\n",
        "    def __init__(self, row):\n",
        "        self._data = row\n",
        "\n",
        "    @property\n",
        "    def path(self):\n",
        "        return self._data[0]\n",
        "\n",
        "    @property\n",
        "    def label(self):\n",
        "        return int(self._data[1])\n",
        "\n",
        "\n",
        "class DFDCDatatset(data.Dataset):\n",
        "    def __init__(self, root_path, list_file, transform=None):\n",
        "        self.root_path = root_path\n",
        "        self.list_file = list_file\n",
        "        self.transform = transform\n",
        "\n",
        "        self._parse_list()\n",
        "\n",
        "    def _load_image(self, image_path):\n",
        "        return Image.open(image_path).convert('RGB')\n",
        "\n",
        "    def _parse_list(self):\n",
        "        self.image_list = [ImageRecord(x.strip().split(' ')) for x in open(self.list_file)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        record = self.image_list[index]\n",
        "        image_name = os.path.join(self.root_path, record.path)\n",
        "        image = self._load_image(image_name)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, record.label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE1XgCFrnyfK"
      },
      "outputs": [],
      "source": [
        "# train / validate\n",
        "\n",
        "def train(train_loader, model, criterion, optimizer, epoch):   \n",
        "    n = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    with tqdm.tqdm(train_loader, total=len(train_loader), desc=\"Train\", file=sys.stdout) as iterator:\n",
        "        for images, target in iterator:\n",
        "            if args.gpu is not None:\n",
        "                images = images.cuda(args.gpu, non_blocking=True)\n",
        "                target = target.cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, pred = torch.max(outputs.data, 1)\n",
        "\n",
        "            loss = criterion(outputs, target)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            n += images.size(0)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(pred == target.data)\n",
        "\n",
        "            epoch_loss = running_loss / float(n)\n",
        "            epoch_acc = running_corrects / float(n)\n",
        "\n",
        "            log = 'loss - {:.4f}, acc - {:.3f}'.format(epoch_loss, epoch_acc)\n",
        "            iterator.set_postfix_str(log)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "def validate(test_loader, model, criterion):\n",
        "    n = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with tqdm.tqdm(valid_loader, total=len(valid_loader), desc=\"Valid\", file=sys.stdout) as iterator:\n",
        "        for images, target in iterator:\n",
        "            if args.gpu is not None:\n",
        "                images = images.cuda(args.gpu, non_blocking=True)\n",
        "                target = target.cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model(images)\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            _, pred = torch.max(output.data, 1)\n",
        "\n",
        "            n += images.size(0)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(pred == target.data)\n",
        "\n",
        "            epoch_loss = running_loss / float(n)\n",
        "            epoch_acc = running_corrects / float(n)\n",
        "\n",
        "            log = 'loss - {:.4f}, acc - {:.3f}'.format(epoch_loss, epoch_acc)\n",
        "            iterator.set_postfix_str(log)\n",
        "\n",
        "    return epoch_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hsYMts4nyfK"
      },
      "source": [
        "### 3-3. 훈련\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision import  models\n",
        "\n",
        "\n",
        "import os\n",
        "import random\n"
      ],
      "metadata": {
        "id": "IsnSzFwSJVim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda:0')\n",
        "    print(\"Use Cuda\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"Use CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnKN9fRHKc1S",
        "outputId": "86158757-3795-4eb5-f8f9-336f86dfb599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use Cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdSYw9jxnyfL",
        "outputId": "bb70c659-45f5-439a-ace1-3ca338c17e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> creating model 'xception'\n",
            "=> model weight best_model is loaded\n"
          ]
        }
      ],
      "source": [
        "model = xception(num_out_classes=2, dropout=0.5)\n",
        "print(\"=> creating model '{}'\".format('xception'))\n",
        "\n",
        "best_model = torch.load(\"/content/drive/My Drive/deepfake/model/origin_realfake.pth.tar\")\n",
        "model.load_state_dict(best_model['state_dict'])\n",
        "print(\"=> model weight best_model is loaded\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TptIAPj4nyfL"
      },
      "outputs": [],
      "source": [
        "train_dataset = DFDCDatatset(args.root,\n",
        "                             args.train_list,\n",
        "                             xception_default[\"train\"],\n",
        "                             )\n",
        "\n",
        "valid_dataset = DFDCDatatset(args.root,\n",
        "                             args.valid_list,\n",
        "                             xception_default[\"valid\"],\n",
        "                             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX3xlvwGnyfM",
        "outputId": "a7ba11c3-89f8-4a29-81e3-c9e837b5c33d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=args.batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=args.num_workers,\n",
        "                                           pin_memory=True,\n",
        "                                           )\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                                           batch_size=args.batch_size,\n",
        "                                           shuffle=False,\n",
        "                                           num_workers=args.num_workers,\n",
        "                                           pin_memory=False,\n",
        "                                           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MPIaVSBnyfM"
      },
      "outputs": [],
      "source": [
        "\n",
        "## epoch = 10\n",
        "print('-' * 50)\n",
        "\n",
        "for i in range(args.num_epochs):\n",
        "    print('Epoch {}/{}'.format(i+1, args.num_epochs))\n",
        "    train(train_loader, model, criterion, optimizer, 0)\n",
        "    acc = validate(valid_loader, model, criterion)\n",
        "\n",
        "max_acc = 0\n",
        "\n",
        "if acc >= max_acc:\n",
        "        save_checkpoint(state={'epoch': args.num_epochs + 1,\n",
        "                               'state_dict': model.state_dict(),\n",
        "                               'best_acc1': acc,\n",
        "                               'optimizer': optimizer.state_dict(),},\n",
        "                        is_best=False,\n",
        "                        filename=args.save_fn,\n",
        "                        )\n",
        "        max_acc = acc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VWve7phn1gaB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "deepfake_detector.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "N2TSMojjZ53G"
      ]
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}