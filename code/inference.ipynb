{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8cujHWkZKoj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba8f84e5-9c86-43c9-e845-ed1c4c4cb6bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import easydict\n",
        "import os\n",
        "import sys\n",
        "from PIL import Image\n",
        "import tqdm\n",
        "import shutil\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torchvision import transforms\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "PxWCNkxyZSLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 719\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "j-_LUyWXZWBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cudnn.benchmark = True\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "    \"gpu\": 0,\n",
        "\n",
        "    \"root\": \"/content/drive/My Drive/deepfake\",\n",
        "    \"valid_list\": \"/content/drive/My Drive/deepfake/Lv6_impulse_test_list.txt\",\n",
        "    \"save_fn\": \"/content/drive/My Drive/deepfake/model/xception_new_model.pth.tar\",\n",
        "})\n",
        "\n",
        "assert os.path.isfile(args.valid_list), 'wrong path'"
      ],
      "metadata": {
        "id": "oxlv8wBNZYN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Author: Andreas Rössler,\n",
        "Implemented in https://github.com/ondyari/FaceForensics under MIT license\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n",
        "        super(SeparableConv2d,self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self,in_filters,out_filters,reps,strides=1,start_with_relu=True,grow_first=True):\n",
        "        super(Block, self).__init__()\n",
        "\n",
        "        if out_filters != in_filters or strides!=1:\n",
        "            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n",
        "            self.skipbn = nn.BatchNorm2d(out_filters)\n",
        "        else:\n",
        "            self.skip=None\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        rep=[]\n",
        "\n",
        "        filters=in_filters\n",
        "        if grow_first:\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(out_filters))\n",
        "            filters = out_filters\n",
        "\n",
        "        for i in range(reps-1):\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(filters))\n",
        "\n",
        "        if not grow_first:\n",
        "            rep.append(self.relu)\n",
        "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(out_filters))\n",
        "\n",
        "        if not start_with_relu:\n",
        "            rep = rep[1:]\n",
        "        else:\n",
        "            rep[0] = nn.ReLU(inplace=False)\n",
        "\n",
        "        if strides != 1:\n",
        "            rep.append(nn.MaxPool2d(3,strides,1))\n",
        "        self.rep = nn.Sequential(*rep)\n",
        "\n",
        "    def forward(self,inp):\n",
        "        x = self.rep(inp)\n",
        "\n",
        "        if self.skip is not None:\n",
        "            skip = self.skip(inp)\n",
        "            skip = self.skipbn(skip)\n",
        "        else:\n",
        "            skip = inp\n",
        "\n",
        "        x+=skip\n",
        "        return x\n",
        "\n",
        "\n",
        "class Xception(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(Xception, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3,32,3,2,0,bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32,64,3,bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.block1=Block(64,128,2,2,start_with_relu=False,grow_first=True)\n",
        "        self.block2=Block(128,256,2,2,start_with_relu=True,grow_first=True)\n",
        "        self.block3=Block(256,728,2,2,start_with_relu=True,grow_first=True)\n",
        "\n",
        "        self.block4=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block5=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block6=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block7=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "\n",
        "        self.block8=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block9=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block10=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block11=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "\n",
        "        self.block12=Block(728,1024,2,2,start_with_relu=True,grow_first=False)\n",
        "\n",
        "        self.conv3 = SeparableConv2d(1024,1536,3,1,1)\n",
        "        self.bn3 = nn.BatchNorm2d(1536)\n",
        "\n",
        "        self.conv4 = SeparableConv2d(1536,2048,3,1,1)\n",
        "        self.bn4 = nn.BatchNorm2d(2048)\n",
        "\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "    def features(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "        x = self.block7(x)\n",
        "        x = self.block8(x)\n",
        "        x = self.block9(x)\n",
        "        x = self.block10(x)\n",
        "        x = self.block11(x)\n",
        "        x = self.block12(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        return x\n",
        "\n",
        "    def logits(self, features):\n",
        "        x = self.relu(features)\n",
        "\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1)) \n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.last_linear(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.features(input)\n",
        "        x = self.logits(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "## 기존 Xception에 Dropout만 추가\n",
        "class xception(nn.Module):\n",
        "    def __init__(self, num_out_classes=2, dropout=0.5):\n",
        "        super(xception, self).__init__()\n",
        "\n",
        "        self.model = Xception(num_classes=num_out_classes)\n",
        "        self.model.last_linear = self.model.fc\n",
        "        del self.model.fc\n",
        "\n",
        "        num_ftrs = self.model.last_linear.in_features\n",
        "        if not dropout:\n",
        "            self.model.last_linear = nn.Linear(num_ftrs, num_out_classes)\n",
        "        else:            \n",
        "            self.model.last_linear = nn.Sequential(\n",
        "                nn.Dropout(p=dropout),\n",
        "                nn.Linear(num_ftrs, num_out_classes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "M6wn1OtNZwG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xception_default = {\n",
        "    'train': transforms.Compose([transforms.CenterCrop((299, 299)),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.RandomHorizontalFlip(),\n",
        "                                 transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "                                 ]),\n",
        "    'valid': transforms.Compose([transforms.CenterCrop((299, 299)),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize([0.5]*3, [0.5]*3),\n",
        "                                 ]),\n",
        "    'test': transforms.Compose([transforms.CenterCrop((299, 299)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.5] * 3, [0.5] * 3),\n",
        "                                ]),\n",
        "}"
      ],
      "metadata": {
        "id": "W7hBV-NmZ33H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom dataset\n",
        "\n",
        "class ImageRecord(object):\n",
        "    def __init__(self, row):\n",
        "        self._data = row\n",
        "\n",
        "    @property\n",
        "    def path(self):\n",
        "        return self._data[0]\n",
        "\n",
        "    @property\n",
        "    def label(self):\n",
        "        return int(self._data[1])\n",
        "\n",
        "\n",
        "class DFDCDatatset(data.Dataset):\n",
        "    def __init__(self, root_path, list_file, transform=None):\n",
        "        self.root_path = root_path\n",
        "        self.list_file = list_file\n",
        "        self.transform = transform\n",
        "\n",
        "        self._parse_list()\n",
        "\n",
        "    def _load_image(self, image_path):\n",
        "        return Image.open(image_path).convert('RGB')\n",
        "\n",
        "    def _parse_list(self):\n",
        "        self.image_list = [ImageRecord(x.strip().split(' ')) for x in open(self.list_file)]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        record = self.image_list[index]\n",
        "        image_name = os.path.join(self.root_path, record.path)\n",
        "        image = self._load_image(image_name)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, record.label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)"
      ],
      "metadata": {
        "id": "N5eYFgWuZ9p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validate\n",
        "\n",
        "def validate(test_loader, model, criterion):\n",
        "    \n",
        "    n = 0\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    correct = 0\n",
        "    classnum = 2\n",
        "    target_num = torch.zeros((1, classnum))\n",
        "    predict_num = torch.zeros((1, classnum))\n",
        "    acc_num = torch.zeros((1, classnum))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with tqdm.tqdm(valid_loader, total=len(valid_loader), desc=\"Valid\", file=sys.stdout) as iterator:\n",
        "        for images, target in iterator:\n",
        "            if args.gpu is not None:\n",
        "                images = images.cuda(args.gpu, non_blocking=True)\n",
        "                target = target.cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model(images)\n",
        "\n",
        "            loss = criterion(output, target)\n",
        "            _, pred = torch.max(output.data, 1)\n",
        "\n",
        "            n += images.size(0)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(pred == target.data)\n",
        "\n",
        "            correct += pred.eq(target.data).cpu().sum()\n",
        "            pre_mask = torch.zeros(output.size()).scatter_(1, pred.cpu().view(-1,1), 1.)\n",
        "            predict_num += pre_mask.sum(0)\n",
        "            tar_mask = torch.zeros(output.size()).scatter_(1, target.data.cpu().view(-1,1), 1.)\n",
        "            target_num += tar_mask.sum(0)\n",
        "            acc_mask = pre_mask * tar_mask\n",
        "            acc_num += acc_mask.sum(0)\n",
        "\n",
        "\n",
        "            epoch_loss = running_loss / float(n)\n",
        "            epoch_acc = running_corrects / float(n)\n",
        "            precision = acc_num / predict_num\n",
        "            recall = acc_num / target_num\n",
        "\n",
        "            recall = recall.numpy()[0].round(3)\n",
        "            precision = precision.numpy()[0].round(3)\n",
        "\n",
        "            f1_score = 2*(precision * recall) / (precision + recall)\n",
        "\n",
        "            recall_ = recall.mean()\n",
        "            precision_ = precision.mean()\n",
        "            f1_score_ = f1_score.mean()\n",
        "\n",
        "            log = 'loss - {0:.4f}, acc - {1:.3f}, precision - {2}, recall - {3}, f1_score - {4} '.format(epoch_loss, epoch_acc, precision_, recall_, f1_score_)\n",
        "            iterator.set_postfix_str(log)\n",
        "\n",
        "    return epoch_acc"
      ],
      "metadata": {
        "id": "wo_ByjnKc7Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = xception(num_out_classes=2, dropout=0.5)\n",
        "print(\"=> creating model '{}'\".format('xception'))\n",
        "model = model.cuda(args.gpu)\n",
        "\n",
        "assert os.path.isfile(args.save_fn), 'wrong path'\n",
        "\n",
        "model.load_state_dict(torch.load(args.save_fn)['state_dict'])\n",
        "print(\"=> model weight '{}' is loaded\".format(args.save_fn))\n",
        "\n",
        "model = model.eval()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()"
      ],
      "metadata": {
        "id": "AsWzveJfarMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37170d11-7486-457d-81a9-0d269fa0352c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> creating model 'xception'\n",
            "=> model weight '/content/drive/My Drive/deepfake/model/xception_new_model.pth.tar' is loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = DFDCDatatset(args.root,\n",
        "                             args.valid_list,\n",
        "                             xception_default[\"test\"],\n",
        "                             )"
      ],
      "metadata": {
        "id": "6qVj1ElIaGt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                                           shuffle=False,\n",
        "                                           pin_memory=False,\n",
        "                                           )"
      ],
      "metadata": {
        "id": "ebBh6KyiaHPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('-' * 50)\n",
        "acc = validate(valid_loader, model, criterion)"
      ],
      "metadata": {
        "id": "Sl0Acqd2aJvi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}